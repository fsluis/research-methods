---
title: "INFOSHEET: INTERVIEWS"
author: "Frans van der Sluis and Mara Gunther"
date: "2025"
output: 
  html_document:
    css: labs_styles.css
---

## Introduction
Semi-structured interviews are qualitative in nature and rely on asking questions within a predetermined thematic framework. They are the most widely employed method in qualitative research, acting as an exploratory tool in marketing, social science, survey methodology, and other research fields.

Semi-structured interviews are often open-ended, allowing for flexibility and providing in-depth insights into specific topics. The method balances structure with flexibility and exploration, enabling interviewers to probe deeper into responses, uncovering rich, qualitative data that might not emerge in more structured formats.

Compared to quantitative surveys, interviews allow for clarification, follow-ups, and deeper exploration of responses and complex issues. At the same time, interviews can also be time-consuming, requiring transcription, coding and a detailed analysis.

## Conducting Interviews at KU DigiLabs
At DigiLabs, you can conduct both individual and group interviews in a controlled setting. We recommend borrowing a Zoom recorder or another high-quality microphone for clear audio capture. Before starting, prepare an interview scheme outlining key questions, follow-ups, and structure (e.g., semi-structured vs. structured interviews). You can consider doing something special, like having your interviewee sort cards as part of the interview (Conrad, 2019), or use ‘props’ to steer a conversation. Align your interview plan with your research questions. Assign roles: Who will lead the interview, and who will be the observer? The interviewer guides the conversation, follows the interview plan, and ensures a natural flow. The observer takes notes on non-verbal behavior, conversation dynamics, and interviewee responses. Finally, reflect on what makes a good interview.

Bryman (2012, pp. 218–224) discusses several best practices, including building rapport, maintaining neutrality, and using probing or prompting techniques to encourage elaboration. After each session, debriefing helps reflect on key insights, unexpected findings, and interactional patterns (Bryman, 2012, p. 225). For further details on interview design, question sequencing, and ethical considerations, refer to Bryman (2012, Chapter 9: Structured Interviewing), and on note taking (Chapter 19.4).

## Analyzing interviews
After each interview, take a debriefing moment to reflect on key insights and unexpected findings. Transfer the recorded interviews to a computer and transcribe them, ensuring accuracy through proofreading, speaker designations, and timestamps. If conducting group interviews, pay special attention to interactional patterns. Combine your transcripts with your observations.


For data analysis, thematic coding is a widely used approach. Braun and Clarke’s method of inductive thematic analysis offers a structured way to identify recurring ideas and patterns. Researchers should generate initial codes by marking relevant text segments, keeping them close to the data (Bryman, 2012, p. 580). Similar codes should be grouped into potential themes, refined through discussion, and structured to ensure coherence and depth. To ensure inter-rater reliability, have multiple researchers code a subset independently, compare results, and resolve discrepancies by revisiting the data or refining definitions collaboratively.
Use card sorting to structure themes and identify relationships. Define and name your final themes clearly, ensuring they provide meaningful insights. Document your analysis process. Use summary statistics to describe your codes (see Stats1). Support your analysis with direct quotes, moving beyond description to explain how themes connect and what they reveal.

<!-- two paragraphs copied from labs2 -->
Triangulation strengthens qualitative research by combining multiple data sources (Bryman, 2012, p. 586). In interview studies, spoken content (transcripts) can be cross-validated with:
- Video analysis, which allows researchers to observe non-verbal cues such as facial expressions, gestures, and body language. These behaviors can reveal underlying sentiments that might not be explicitly stated in conversation. At KU DigiLabs, researchers can use Observer XT to code and analyze these non-verbal interactions systematically.
- Prosodic speech analysis examines how participants speak. Changes in pitch, tone, speed, and stress can indicate emotional states that are difficult to detect from transcripts alone. For instance, an increase in pitch might suggest excitement or nervousness, while a slow and hesitant response could indicate uncertainty or reluctance. At KU DigiLabs, we use tools like WASP to analyze speech parameters.

While interview studies are primarily qualitative, **descriptive statistics** (Stats1) can be used to count how often specific themes or behaviors occur. For example, if "trust in information" appears in 75% of transcripts, this suggests a recurring concern. Similarly, researchers can track the number of interruptions, speech duration, or expressions of hesitation to quantify engagement levels.
**Relational statistics** (Stats2 and Stats3) allow researchers to correlate different data sources. By analyzing whether certain themes in transcripts align with specific body language patterns or vocal stress markers, researchers can test hypotheses about participant confidence, uncertainty, or emotional responses. For instance, if discussions about misinformation consistently coincide with higher vocal pitch and increased speech rate, it might indicate anxiety or cognitive strain. 

For further details on thematic analysis, coding techniques, and reliability checks, see Bryman (2012, Chapter 24: Qualitative Data Analysis).



## Additional resources and references:
- Bryman chapter 9, 19 and 24
- Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77–101. https://doi.org/10.1191/1478088706qp063oa
- Conrad, L. Y., & Tucker, V. M. (2019). Making it tangible: Hybrid card sorting within qualitative interviews. Journal of Documentation, 75(2), 397–416. https://doi.org/10.1108/JD-06-2018-0091

## Example Study: Collaboration in Data-Intensive Research Networks

This study explores how Ph.D. fellows in wind energy research networks navigate collaboration challenges and expectations in interdisciplinary, data-intensive environments. Given the reliance on shared data, infrastructure, and international teams, collaboration is crucial yet complex.

Reference:

Fraumann, G., Lund, H., van der Sluis, F., & Hertzum, M. (2025). Collaboration in data-intensive research networks: Expectations of Ph.D. fellows [work in progress / not published yet].

Methodology:

Researchers conducted semi-structured interviews with 23 Ph.D. fellows across four research networks, analyzing responses through inductive thematic analysis and card sorting. Participants discussed knowledge sharing, network interactions, and institutional support, with themes refined collaboratively through investigator triangulation.

Key Findings:

- Collaboration is a balancing act between institutional goals, network demands, and personal priorities.
- Optimistic expectations contrast with the realities of coordinating interdisciplinary work.
- Data defines collaboration, influencing partnerships and dependencies.
- Physical meetings remain essential for building trust, despite reliance on digital tools.

Relevance:
This study demonstrates how semi-structured interviews and inductive analysis can reveal social dynamics in research collaborations. The card sorting method provides a structured way to develop themes from qualitative data, making it a valuable approach for analyzing group discussions and professional interactions in lab settings.


## Example studies
Gwynne, A. E. (2024). ‘Up to you’: Self-help books, depression and the reconstruction of reading. Media, Culture & Society, 46(2), 324-342. https://doi.org/10.1177/01634437231198431

Broomfield, H., & Reutter, L. (2021). Towards a data-driven public administration: An empirical analysis of nascent phase implementation. Scandinavian Journal of Public Administration, 25(2), 73-97. doi:https://doi.org/10.58235/sjpa.v25i2.7117

Madell, D. E., & Muncer, S. J. (2007). Control over Social Interactions: An Important Reason for Young People’s Use of the Internet and Mobile Phones for Communication? CyberPsychology & Behavior, 10(1), 137–140. https://doi.org/10.1089/cpb.2006.9980 

Derges, J., Bould, H., Gooberman-Hill, R., Moran, P., Linton, M., Rifkin-Zybutz, R., & Biddle, L. (2023). Mental health practitioners’ and young people’s experiences of talking about social media during mental health consultations: Qualitative focus group and interview study. JMIR Formative Research, 7, e43115. https://doi.org/10.2196/43115







